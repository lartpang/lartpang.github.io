<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Homepage" />
  <meta name="keywords" content="Homepage" />
  <meta name="author" content="Lart Pang" />
  <title>ZoomNet-CVPR2022</title>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@1.0.1/css/bulma.min.css">
  <link rel="apple-touch-icon" href="apple-touch-icon.png" />
  <link rel="icon" href="favicon.ico" />
  <style>
    body {
      font-family: Georgia, serif;
    }
  </style>
</head>

<body>
  <nav class="navbar is-white" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://lartpang.github.io">
        <svg t="1723627295537" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="13432" width="200" height="200">
          <path d="M484.32 375.24C575.25 255.5 857.87 527.6 788.67 581.07c-94.76 73.21-491.01 39.99-304.35-205.83z" fill="#1C80AA" p-id="13433"></path>
          <path d="M401.03 749.89l-4.85 133.8-77.69 21.37h66.36l19.42 35.27 4.86-35.27 40.46 6.14-38.84-25.89 8.09-114.91-17.81-20.51zM524.36 771.23l10.48 133.48-74.73 30.11 65.92-7.59 23.33 32.82 0.79-35.6 40.89 1.48-41.54-21.28-5.11-115.08-20.03-18.34z" fill="#3B5174" p-id="13434"></path>
          <path d="M224.73 264.77l-24 50.19a21.7 21.7 0 0 1-37.73 2.5l-31.57-48.27a21.7 21.7 0 0 1 17.41-33.57l55.61-1.92a21.7 21.7 0 0 1 20.28 31.07z" fill="#DE7B56" p-id="13435"></path>
          <path d="M900.53 638.76c-18.3 86.91-221.86 208.13-478 171.54C150.46 771.44 26 281.88 315 103.56c161.25-99.49 326.71 5 356.8 130.37C713 405.47 583.15 534.58 749.57 609c86.91 38.91 164.43-34.33 150.96 29.76z" fill="#FDD2BE" p-id="13436"></path>
          <path d="M365.86 264.78m-32.45 0a32.45 32.45 0 1 0 64.9 0 32.45 32.45 0 1 0-64.9 0Z" fill="" p-id="13437"></path>
          <path d="M512.24 366c137.48-60.86 253.34 314 166.92 327.31C560.81 711.56 230 490.92 512.24 366zM223.3 530c-9.34-2.6-17.2-12.8-23.94-31a195 195 0 0 1-7.64-27 7.28 7.28 0 0 1 14.3-2.79c4.79 24.5 15 46.44 21.91 46.93 1.12 0.08 11.43-0.5 27.23-45.51a7.28 7.28 0 1 1 13.74 4.82c-13.61 38.77-27 56.31-42 55.22a18.18 18.18 0 0 1-3.6-0.67zM340.8 590.36c-9.63 1.14-20.77-5.32-33.92-19.63a195 195 0 0 1-17.32-22.11 7.28 7.28 0 0 1 12.17-8c13.73 20.85 31.53 37.27 38.07 35.12 1.07-0.35 10.38-4.8 7.93-52.44a7.28 7.28 0 1 1 14.55-0.75c2.11 41-3.59 62.33-17.95 67a18.18 18.18 0 0 1-3.53 0.81zM261.5 659.71c-9-0.19-18.35-7.55-28.56-22.35a180.41 180.41 0 0 1-13-22.49 6.74 6.74 0 0 1 12.18-5.77c9.9 20.88 24.1 38.21 30.37 37.08 1-0.18 10.13-3.07 14-47a6.74 6.74 0 1 1 13.43 1.18c-3.34 37.87-11.31 56.66-25.07 59.12a16.82 16.82 0 0 1-3.35 0.23zM389.28 722.29c-9.26 2.85-21.38-1.51-36.89-13.22a195 195 0 0 1-21-18.64 7.28 7.28 0 0 1 10.53-10.06c17.25 18.05 37.7 31 43.75 27.71 1-0.54 9.35-6.59-1.61-53a7.28 7.28 0 1 1 14.17-3.35c9.44 40 7.65 62-5.63 69.16a18.18 18.18 0 0 1-3.32 1.4z" fill="#22B0C3" p-id="13438"></path>
        </svg>
      </a>

      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbar_">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div id="navbar_" class="navbar-menu">
      <div class="navbar-start">
        <a class="navbar-item" href="#abstract">üëã Abstract</a>
        <a class="navbar-item" href="#links">üîó Related Links</a>
        <a class="navbar-item" href="#method">üìñ ZoomNet</a>
      </div>

    </div>
  </nav>

  <section class="section has-background-white-ter">
    <div class="container">
      <div class="columns">

        <div class="column">

          <div class="card" id="banner">
            <div class="card-image">
              <figure class="image is-3by1">
                <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/net.png?raw=true" alt="Avatar" />
              </figure>
            </div>

            <div class="card-content">
              <div class="media">
                <div class="media-content">
                  <div class="has-text-centered">
                    <span class="title is-4">Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection</span>
                    <br />
                    <span class="paper-author"><span class="author-me">Youwei Pang</span>*, Xiaoqi Zhao*, Tian-zhu Xiang, Lihe Zhang, Huchuan Lu</span>.
                    <br />
                    <span class="paper-conf">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022, IEEE</span>

                    <p>
                      <a href="https://opensource.org/licenses/MIT" target="_blank"><img src="https://img.shields.io/badge/License-MIT-green.svg" alt="license: mit"></a>
                      <img src="https://img.shields.io/github/last-commit/lartpang/ZoomNet?style=flat-square" alt="LAST COMMIT">
                      <img src="https://img.shields.io/github/issues/lartpang/ZoomNet?style=flat-square" alt="ISSUES">
                      <img src="https://img.shields.io/github/stars/lartpang/ZoomNet?style=flat-square" alt="STARS">
                      <a href="https://arxiv.org/abs/2203.02688" target="_blank"><img src="https://img.shields.io/badge/Arxiv-Paper-red?style=flat-square" alt="paper"></a>
                      <a href="https://github.com/lartpang/ZoomNet/releases/download/v0.0.1/zoomnet-arxiv.pdf" target="_blank"><img src="https://img.shields.io/badge/Github-Paper-red?style=flat-square" alt="paper"></a>
                    </p>
                  </div>

                  <div class="tags has-text-weight-bold is-centered">
                    <span class="tag-link"><a href="https://arxiv.org/abs/2203.02688" target="_blank">[Paper]</a></span>
                    <span class="tag-link"><a href="https://github.com/lartpang/ZoomNet" target="_blank">[Code]</a></span>
                    <span class="tag-link"><a href="/docs/zoomnet.html" target="_blank">[Project]</a></span>
                  </div>

                  <details>
                    <summary>üñêÔ∏è BibTeX (<code>ZoomNet-CVPR2022</code>)</summary>
                    <pre>@inproceedings{ZoomNet-CVPR2022,
  title = {Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection},
  author = {Pang, Youwei and Zhao, Xiaoqi and Xiang, Tian-Zhu and Zhang, Lihe and Lu, Huchuan},
  booktitle = CVPR,
  year = {2022}
}</pre>
                  </details>
                </div>
              </div>
            </div>
          </div>

          <div class="box" id="abstract">
            <p class="title is-4">üëã Abstract</p>

            <p>
              The recently proposed camouflaged object detection (COD) attempts to segment objects that are visually blended into their surroundings, which is extremely complex and difficult in real-world scenarios.
              Apart from high intrinsic similarity between the camouflaged objects and their background, the objects are usually diverse in scale, fuzzy in appearance, and even severely occluded.
              To deal with these problems, we propose a mixed-scale triplet network, \textbf{ZoomNet}, which mimics the behavior of humans when observing vague images, i.e., zooming in and out.
              Specifically, our ZoomNet employs the zoom strategy to learn the discriminative mixed-scale semantics by the designed scale integration unit and hierarchical mixed-scale unit, which fully explores imperceptible clues between the candidate objects and background surroundings.
              Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization constraint, uncertainty-aware loss, to promote the model to accurately produce predictions with higher confidence in candidate regions.
              Without bells and whistles, our proposed highly task-friendly model consistently surpasses the existing 23 state-of-the-art methods on four public datasets.
              Besides, the superior performance over the recent cutting-edge models on the SOD task also verifies the effectiveness and generality of our model.
            </p>
          </div>

          <div class="box" id="links">
            <p class="title is-4">üîó Related Links</p>

            <table class="table is-striped is-narrow is-fullwidth">
              <thead>
                <tr>
                  <th>Task</th>
                  <th>Weights</th>
                  <th>Results</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>COD</td>
                  <td><a href="https://github.com/lartpang/ZoomNet/releases/download/v0.0.1/cod_zoomnet_r50_bs8_e40_2022-03-04.pth">GitHub Release Link</a></td>
                  <td><a href="https://github.com/lartpang/ZoomNet/releases/download/v0.0.1/CVPR-2022-ZoomNet-COD.zip">GitHub Release Link</a></td>
                </tr>
                <tr>
                  <td>SOD</td>
                  <td><a href="https://github.com/lartpang/ZoomNet/releases/download/v0.0.1/sod_zoomnet_r50_bs22_e50_2022-03-04_fixed.pth">GitHub Release Link</a></td>
                  <td><a href="https://github.com/lartpang/ZoomNet/releases/download/v0.0.1/CVPR-2022-ZoomNet-SOD.zip">GitHub Release Link</a></td>
                </tr>
              </tbody>
            </table>

            <div class="content">
              <ul>
                <li>The prediction maps corresponding to the methods in Table 1 of our paper: <a href="https://pan.baidu.com/s/1dLMqa4tix1gdBN1uWrCPbQ" target="_blank">Baidu Pan (yxy9)</a></li>
                <li><a href="https://github.com/lartpang/PySODEvalToolkit" target="_blank">PySODEvalToolkit</a>: A Python-based Evaluation Toolbox for Salient Object Detection and Camouflaged Object Detection</li>
                <li><a href="https://github.com/lartpang/awesome-segmentation-saliency-dataset#camouflaged-object-detection-cod" target="_blank">COD Datasets</a></li>
                <li><a href="https://github.com/lartpang/awesome-segmentation-saliency-dataset#rgb-saliency" target="_blank">SOD Datasets</a></li>
              </ul>
            </div>
          </div>

          <div class="box" id="method">
            <p class="title is-4">üìñ ZoomNet</p>

            <div class="block" id="model">
              <p class="subtitle is-5">Method Details</p>

              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/feat.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>

              <div class="columns is-centered">
                <div class="column is-three-quarters">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/net.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>
            </div>

            <div class="block" id="experiment">
              <p class="subtitle is-5">Experiment</p>

              <p class="subtitle is-6">Camouflaged Object Detection</p>
              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/cod_vis.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>
              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/cod_cmp.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>
              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/cod_fmpr.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>

              <p class="subtitle is-6">Salient Object Detection</p>
              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/sod_cmp.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>
              <div class="columns is-centered">
                <div class="column">
                  <figure class="image">
                    <img src="https://github.com/lartpang/ZoomNet/blob/main/assets/sod_fmpr.png?raw=true" alt="zoomnet">
                  </figure>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer py-4">
    <div class="content has-text-centered">
      Last updated at <time datetime="YYYY-MM-DD">2024-09-03</time>
      ¬© 2024 Youwei Pang. All rights reserved.
    </div>
  </footer>
</body>

<script>
  // ÂÆö‰πâÊò†Â∞ÑÂÖ≥Á≥ª
  const classMap = {
    'paper-title': ['has-text-weight-bold'],
    'paper-author': ['is-italic'],
    'paper-conf': ['has-text-weight-semibold'],
    'author-me': ['has-text-info', 'has-text-weight-bold'],
    'tag-link': ['tag', 'is-light', 'has-text-weight-bold'],
    'caption': ['is-italic', 'has-text-centered']
  };

  // ÊõøÊç¢Á±ªÂà´Âêç‰∏∫ÂÆûÈôÖÁöÑÁ±ªÂÆö‰πâ
  function replaceClassAliases() {
    // ÈÅçÂéÜÊò†Â∞Ñ‰∏≠ÁöÑÊØè‰∏™Âà´Âêç
    Object.keys(classMap).forEach(alias => {
      // Êü•Êâæ‰ΩøÁî®Âà´ÂêçÁöÑÊâÄÊúâÂÖÉÁ¥†
      document.querySelectorAll('.' + alias).forEach(element => {
        // ÁßªÈô§Âà´ÂêçÁ±ª
        element.classList.remove(alias);
        // Ê∑ªÂä†Êò†Â∞ÑÂà∞ÁöÑÂÆûÈôÖÁ±ª
        classMap[alias].forEach(actualClass => {
          element.classList.add(actualClass);
        });
      });
    });
  }

  // navbar active, https://bulma.io/documentation/components/navbar/#navbar-menu
  function activateNavbarMenu() {
    // Get all "navbar-burger" elements
    const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
    // Add a click event on each of them
    $navbarBurgers.forEach(el => {
      el.addEventListener('click', () => {
        // Get the target from the "data-target" attribute
        const target = el.dataset.target;
        const $target = document.getElementById(target);
        // Toggle the "is-active" class on both the "navbar-burger" and the "navbar-menu"
        el.classList.toggle('is-active');
        $target.classList.toggle('is-active');
      });
    });
  }

  // Âú®ÊñáÊ°£Âä†ËΩΩÂÆåÊàêÂêéÊâßË°åÊõøÊç¢
  document.addEventListener('DOMContentLoaded', () => {
    replaceClassAliases();
    activateNavbarMenu();
  });
</script>

</html>
